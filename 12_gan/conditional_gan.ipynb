{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/machine-perception-robotics-group/MPRGDeepLearningLectureNotebook/blob/master/12_gan/04_conditional_DC_GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QAT-iz9wcBRX"
   },
   "source": [
    "# Conditional GAN (cGAN)\n",
    "\n",
    "---\n",
    "## 目的\n",
    "条件付きのGANによって意図した画像の生成をして動作を理解する．\n",
    "\n",
    "## 必要なモジュールのインポート\n",
    "Pytorchで学習するときに必要となるモジュールをインポートします．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tgdqg3P_cBRY"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ylhOosV_cBRb"
   },
   "source": [
    "## ネットワークの構築\n",
    "基本的なネットワーク構造は，通常のGANと同様で全結合層で設計します．\n",
    "ただ，cGANでは条件の入力があるため，Generator及びDiscriminatorの入力層のチャネル数がクラス数分多くなっています．\n",
    "\n",
    "<img src=\"https://dl.dropboxusercontent.com/s/42tfm9viymbqemo/cGAN.png\" width=50%>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BZc2vUnFcBRb"
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim=100, n_cls=10):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential()\n",
    "\n",
    "        self.model.add_module('fc1', nn.Linear(latent_dim + n_cls, 128))\n",
    "        self.model.add_module('act1', nn.ReLU(inplace=True))\n",
    "        self.model.add_module('fc2', nn.Linear(128, 32 * 32))\n",
    "        self.model.add_module('act2', nn.ReLU(inplace=True))\n",
    "#         self.weight_init()\n",
    "\n",
    "    def weight_init(self):\n",
    "        for m in self.model:\n",
    "            if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d):\n",
    "                m.weight.data.normal_(0.0, 0.02)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.model(z)\n",
    "    \n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, n_input=32*32, n_cls=10, img_size=32):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential()\n",
    "        \n",
    "        self.model.add_module('fc1', nn.Linear(n_input+n_cls, 128))\n",
    "        self.model.add_module('act1', nn.ReLU(inplace=True))        \n",
    "        self.model.add_module('fc2', nn.Linear(128, 1))\n",
    "#         self.weight_init()\n",
    "  \n",
    "    def weight_init(self):\n",
    "        for m in self.model:\n",
    "            if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d):\n",
    "                m.weight.data.normal_(0.0, 0.02)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x).view(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E-Lp4ruhcBRe"
   },
   "source": [
    "## データセットと最適化関数\n",
    "データセットにはMNISTを使用します．\n",
    "最適化関数はAdam optimizer使用し，学習率$2\\times 10^4$，betaの値を$0.5, 0.999$として学習します．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IEkygtEVdNxt"
   },
   "outputs": [],
   "source": [
    "class MNIST_Loader(Dataset):\n",
    "    def __init__(self, train=True, download=True, transform=None):\n",
    "        self.transform = transform\n",
    "        self.url = 'https://www.dropbox.com/s/hc7ukm7vzst5e40/MNIST.zip?dl=1'\n",
    "\n",
    "        if download:\n",
    "            self._download()\n",
    "\n",
    "        dname = os.path.join(self.url.rpartition('/')[2][:-9], 'processed')\n",
    "        if train:\n",
    "            datapath = os.path.join(dname, 'training.pt')\n",
    "        else:\n",
    "            datapath = os.path.join(dname, 'test.pt')\n",
    "\n",
    "        self.data = torch.load(datapath)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data[0])\n",
    "\n",
    "    def _download(self):\n",
    "        filename = self.url.rpartition('/')[2][:-5]\n",
    "        urllib.request.urlretrieve(self.url, filename)\n",
    "\n",
    "        with zipfile.ZipFile(filename) as existing_zip:\n",
    "            existing_zip.extractall()\n",
    "        os.remove(filename)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        image = transforms.ToPILImage()(self.data[0][i])\n",
    "        label = self.data[1][i]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OdRDwhBkcBRe",
    "outputId": "bb309a46-3ed1-4f2e-9e20-fddea1895cd3"
   },
   "outputs": [],
   "source": [
    "transform_training = transforms.Compose([\n",
    "        transforms.Resize((32, 32)),\n",
    "        transforms.ToTensor()])\n",
    "try:\n",
    "    mnist_data = datasets.MNIST(root='./data', train=True, transform=transform_training, download=True)\n",
    "except:\n",
    "    print('Warning: Switch the original implementation because official MNIST data did not download (probably the official server has down).')\n",
    "    mnist_data = MNIST_Loader(train=True, download=True, transform=transform_training)\n",
    "print('Done!') \n",
    "training_data = DataLoader(mnist_data, batch_size=100, shuffle=True)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "latent_dim = 100\n",
    "cls_num = 10\n",
    "G = Generator(latent_dim=latent_dim, n_cls=cls_num).to(device)\n",
    "D = Discriminator(n_input=32*32, n_cls=cls_num).to(device)\n",
    "opt_g = optim.Adam(G.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "opt_d = optim.Adam(D.parameters(), lr=0.0002, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KGQw9OlBcBRg"
   },
   "source": [
    "## GANの学習\n",
    "ここでは，Generator及びDiscriminatorを用いてGANの学習をします．<br>\n",
    "GANの目的関数は以下に示す式です．\n",
    "$$\n",
    "\\min_{G}\\max_{D}V(D, G) = \\mathbb{E}_{x\\sim P_{data}(x)}\\left[\\log\\left(D(x)\\right)\\right] + \\mathbb{E}_{z\\sim P(z)}\\left[\\log\\left(1 - D(\\hat{x})\\right)\\right]\n",
    "$$\n",
    "GANを学習する際は，binary cross entopyを用いて学習します．実画像は1に，生成画像は0に近似するように学習をします．\n",
    "Discriminatorは，実画像は1生成画像は0と識別するとように学習をしますが，Generatorは生成した画像を実画像であるとDiscriminatorに誤識別をさせたいので，1と識別されるように学習をします．\n",
    "\n",
    "これによりGANの醍醐味である敵対学習を完成させることができます．<br>\n",
    "ここで，n_epochは学習回数です．n_criticはdiscriminatorを1 iterationで何回更新するかの数となっています．<br>\n",
    "Discriminatorを複数回更新した後にGeneratorを1回更新する理由は，モード崩壊を防止するためです．モード崩壊とは，GANの学習では深刻な問題で，Generatorがある一定の画像しか生成できなることや全く画像が生成できなくなることを指します．<br>\n",
    "Discriminatorは，おバカすぎてもダメで，賢すぎてもダメなのでいい塩梅をn_criticの"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "botB5C8lcBRg",
    "outputId": "125d07ea-28dd-4524-ebf8-72f76a41172b"
   },
   "outputs": [],
   "source": [
    "n_epoch = 20\n",
    "n_critic = 1\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "for epoch in range(1, n_epoch+1):\n",
    "    Tensor = torch.cuda.FloatTensor\n",
    "    for idx, (real_x, y) in enumerate(training_data):\n",
    "        real_x = real_x.to(device)\n",
    "        batch = real_x.size(0)\n",
    "        real_x = real_x.view(batch, -1)\n",
    "        onehot = torch.eye(cls_num)[y].to(device)[:,:]\n",
    "        onehot_expand = onehot.expand(batch, onehot.size(1))\n",
    "        flag_real = Tensor(batch).fill_(1.0)\n",
    "        flag_fake = Tensor(batch).fill_(0.0)\n",
    "        \n",
    "        for _ in range(n_critic):\n",
    "            D.zero_grad()\n",
    "            z = torch.randn(batch, latent_dim+cls_num).to(device)\n",
    "            z[:, :10] = onehot\n",
    "            fake_x = G(z)\n",
    "            _real_x = torch.cat((real_x, onehot_expand), dim=1)\n",
    "            _fake_x = torch.cat((fake_x, onehot_expand), dim=1)\n",
    "            out_real = D(_real_x)\n",
    "            out_fake = D(_fake_x.detach())\n",
    "            loss_real = criterion(out_real, flag_real)\n",
    "            loss_fake = criterion(out_fake, flag_fake)\n",
    "            dis_loss = loss_real + loss_fake\n",
    "            dis_loss.backward()\n",
    "            opt_d.step()\n",
    "            \n",
    "        G.zero_grad()\n",
    "        z = torch.randn(batch, latent_dim+cls_num).to(device)\n",
    "        z[:, :10] = onehot\n",
    "        fake_x = G(z)\n",
    "        fake_x = torch.cat((fake_x, onehot_expand), dim=1)\n",
    "        out_gen = D(fake_x)\n",
    "        gen_loss = criterion(out_gen, flag_real)\n",
    "        gen_loss.backward()\n",
    "        opt_g.step()\n",
    "        \n",
    "        if idx % 100 == 0:\n",
    "            print('Training epoch: {} [{}/{} ({:.0f}%)] | D loss: {:.6f} | G loss: {:.6f} |'\\\n",
    "                  .format(epoch, idx * len(real_x), len(training_data.dataset),\n",
    "                  100. * idx / len(training_data), dis_loss.item(), gen_loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ExfsKeWTcBRl"
   },
   "source": [
    "## 生成画像の確認\n",
    "学習済みのGeneratorを用いてどのような画像が生成されるのか，狙った画像を生成することができるのかを確認しましょう．<br>\n",
    "下に書いてあるコードは，今日の日付を生成するようにGeneratorへ条件を入力しています．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 82
    },
    "id": "ejWBDD8jcBRl",
    "outputId": "c19a66b4-e841-425d-cbd3-0fd0b886fb0b"
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "now = datetime.datetime.now(\n",
    "    datetime.timezone(datetime.timedelta(hours=9)))\n",
    "year = now.year\n",
    "month = now.month\n",
    "day = now.day\n",
    "today = (str(year) + str(month).zfill(2) + str(day).zfill(2))\n",
    "today_list = [int(num) for num in today]\n",
    "\n",
    "c = np.asarray(today_list, dtype=np.int32)\n",
    "onehot = torch.eye(10)[c].cuda()[:,:]\n",
    "z = torch.randn(len(c), 100+10).cuda()\n",
    "z[:, :10] = onehot\n",
    "test_img = G(z)\n",
    "_test_img = (test_img * 256.).clamp(min=0., max=255.).data.cpu().view(len(c), 32, 32).numpy()\n",
    "\n",
    "fig = plt.figure(figsize=(10, 3))\n",
    "for i, im in enumerate(_test_img):\n",
    "    ax = fig.add_subplot(3, 10, i+1, xticks=[], yticks=[])\n",
    "    ax.imshow(im, 'gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "245o9OnfeXmp"
   },
   "source": [
    "# 課題\n",
    "* 条件を固定して線形補間したとき，どのような変化が現れるか確認してください．生成画像AからBへの線形補間は，[0, 1]で線形増加する値$\\alpha$を用いて以下の式で表せます．<br>\n",
    "$$\n",
    "\\hat{z} = (1-\\alpha)\\cdot z_{A} + \\alpha\\cdot z_{B}\\\\\n",
    "I_{A\\rightarrow B} = G(\\hat{z})\n",
    "$$\n",
    "* データセットをMNISTからCIFAR-10に変えて学習してみてください．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YUprNLHcqDEX"
   },
   "source": [
    "# 参考文献\n",
    "[1] Mehdi Mirza and Simon Osindero, Conditional Generative Adversarial Nets, arXiv, 2014.\\\n",
    "[2] Alec Radford, Luke Metz and Soumith Chintala, Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks, ICLR, 2016."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "04_conditional_DC-GAN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
