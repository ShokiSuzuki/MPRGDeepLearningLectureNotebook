{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffb46f71-5780-4294-b210-b57e2f2141b4",
   "metadata": {},
   "source": [
    "# 繰り返し処理による異常検知\n",
    "\n",
    "---\n",
    "## 目的\n",
    "\n",
    "Auto Encoder (AE) を用いた繰り返し処理による異常検知の仕組みについて理解する．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c720cd-14dc-4081-a925-67019b6b1e2c",
   "metadata": {},
   "source": [
    "## 準備\n",
    "\n",
    "### Google Colaboratoryの設定確認・変更\n",
    "本チュートリアルではPyTorchを利用してニューラルネットワークの実装を確認，学習および評価を行います．\n",
    "**GPUを用いて処理を行うために，上部のメニューバーの「ランタイム」→「ランタイムのタイプを変更」からハードウェアアクセラレータをGPUにしてください．**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57223e24-83f1-40f4-aabd-1139845a3a34",
   "metadata": {},
   "source": [
    "## モジュールのインポート\n",
    "はじめに必要なモジュールをインポートする．\n",
    "\n",
    "### GPUの確認\n",
    "GPUを使用した計算が可能かどうかを確認します．\n",
    "\n",
    "`GPU availability: True`と表示されれば，GPUを使用した計算をChainerで行うことが可能です．\n",
    "Falseとなっている場合は，上記の「Google Colaboratoryの設定確認・変更」に記載している手順にしたがって，設定を変更した後に，モジュールのインポートから始めてください．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c785c9a4-bb12-47f0-bae5-2983bc13f510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# モジュールのインポート\n",
    "import os\n",
    "from time import time\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# GPUの確認\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print('Use CUDA:', use_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3398b0-4016-42ce-a672-ad9a4970768e",
   "metadata": {},
   "source": [
    "## データセット\n",
    "\n",
    "**MVTec-AD**\n",
    "\n",
    "演習に使用するデータセット\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc10efa-9003-450f-91ad-1ff4c7387cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget http://www.mprg.cs.chubu.ac.jp/~hirakawa/share/tutorial_data/anomaly_detection_data.zip\n",
    "!unzip anomaly_detection_data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e3ecdc-d547-440b-bf0c-3ee15507f2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MVTecAD(torch.utils.data.Dataset):\n",
    "    def __init__(self, image_dir, transform):\n",
    "        self.transform = transform\n",
    "        self.image_dir = image_dir\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(os.listdir(self.image_dir))\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        filename = '{:0>3}.png'.format(i)\n",
    "        image = Image.open(os.path.join(self.image_dir, filename))\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, torch.zeros(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e251951a-d7ae-4c92-bde1-47bff779b75c",
   "metadata": {},
   "source": [
    "## ネットワークモデル\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c07cb6-10ee-46fa-bb9f-dd8b5417eb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, z_dim=100, input_c=1):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        self.z_dim = z_dim\n",
    "        \n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "                nn.Conv2d(input_c, 32, kernel_size=4, stride=2, padding=1), # 128 -> 64\n",
    "                nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "                nn.Conv2d(32, 32, kernel_size=4, stride=2, padding=1),      # 64 -> 32 \n",
    "                nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "                nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1),      # 32 -> 32\n",
    "                nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "                nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=1),      # 32 -> 16\n",
    "                nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "                nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),      # 16 -> 16\n",
    "                nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "                nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),     # 16 -> 8\n",
    "                nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "                nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=1),     # 8 -> 8\n",
    "                nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "                nn.Conv2d(64, 32, kernel_size=3, stride=1, padding=1),      # 8 -> 8\n",
    "                nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "                nn.Conv2d(32, z_dim, kernel_size=8, stride=1)               # 8 -> 1\n",
    "            )\n",
    "        \n",
    "        self.mu_fc = nn.Linear(z_dim, z_dim)\n",
    "        self.logvar_fc = nn.Linear(z_dim, z_dim)\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=8, mode='nearest'),\n",
    "            nn.Conv2d(z_dim, 32, kernel_size=3, stride=1, padding=1),  # 1 -> 8\n",
    "            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),     # 8 -> 8\n",
    "            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),    # 8 -> 8\n",
    "            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "            nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "            nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=1),    # 8 -> 16\n",
    "            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),     # 16 -> 16\n",
    "            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "            nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "            nn.Conv2d(64, 32, kernel_size=3, stride=1, padding=1),     # 16 -> 32\n",
    "            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1),     # 32 -> 32\n",
    "            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "            nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1),     # 32 -> 64\n",
    "            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "            nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "            nn.Conv2d(32, input_c, kernel_size=3, stride=1, padding=1),  # 64 -> 128\n",
    "            nn.Sigmoid())\n",
    "\n",
    "    def initialize(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d) or isinstance(m, nn.LayerNorm):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        #std = logvar.mul(0.5).exp_()\n",
    "        #eps = std.new(std.size()).normal_()\n",
    "        #return eps.mul(std).add_(mu)\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "\n",
    "    def forward(self, x):\n",
    "        h      = self.encoder(x)\n",
    "        \n",
    "        h = torch.flatten(h, start_dim=1)\n",
    "        mu     = self.mu_fc(h)                    # 平均ベクトル\n",
    "        logvar = self.logvar_fc(h)                # 分散共分散行列の対数\n",
    "        z      = self.reparameterize(mu, logvar)  # 潜在変数\n",
    "\n",
    "        x_hat  = self.decoder(z.view(z.size(0), -1, 1, 1))\n",
    "        self.mu     = mu.squeeze()\n",
    "        self.logvar = logvar.squeeze()\n",
    "        return x_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499b6ff5-f689-4643-ba8f-fb5ba2225750",
   "metadata": {},
   "source": [
    "## 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba30206-8068-4f26-b5b5-af85c04fce11",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "batch_size = 10\n",
    "\n",
    "# 誤差関数\n",
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    recon = F.binary_cross_entropy(recon_x, x, reduction='sum')\n",
    "    kld = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return recon + kld, recon, kld\n",
    "\n",
    "# データセットの設定\n",
    "transform = transforms.Compose([\n",
    "                transforms.Resize((128, 128)),\n",
    "                transforms.RandomAffine(degrees=[-60, 60], translate=(0.1, 0.1), scale=(0.5, 1.5)),\n",
    "                transforms.RandomHorizontalFlip(p=0.5),\n",
    "                transforms.RandomVerticalFlip(p=0.5),\n",
    "                transforms.ToTensor()\n",
    "            ])\n",
    "train_data = MVTecAD(image_dir=\"./mvtec_anomaly_detection/capsule/train/good\", transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=40)\n",
    "\n",
    "# ネットワークモデル・最適化手法の設定\n",
    "model = VAE(z_dim=100, input_c=3)\n",
    "if use_cuda:\n",
    "    model = model.cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-4, betas=(0.5, 0.999), weight_decay=1e-5)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(1, epochs + 1):\n",
    "    for idx, (inputs, _) in enumerate(train_loader):\n",
    "        if use_cuda:\n",
    "            inputs = inputs.cuda()\n",
    "        output = model(inputs)\n",
    "        loss, _, _ = loss_function(output, inputs, model.mu, model.logvar)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if idx % 100 == 0 and epoch % 10 == 0:\n",
    "            print('%d epoch [%d/%d] | loss: %.4f |' % (epoch, idx, len(train_loader), loss.item()))\n",
    "            \n",
    "    if epoch % 100 == 0:\n",
    "        torch.save(model.state_dict(), \"snapshot-mvtec/capsule_vae/anomaly_det_model_%04d.pt\" % epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4931a299-4719-4f09-b219-a18d21c2b1fc",
   "metadata": {},
   "source": [
    "### テスト（学習データで）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588f4a7f-b256-478a-9cbc-25e920589b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"snapshot-mvtec/capsule_vae/anomaly_det_model_1000.pt\"))\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for ind, (inputs, _) in enumerate(train_loader):\n",
    "        if use_cuda:\n",
    "            inputs = inputs.cuda()\n",
    "            \n",
    "        reconstructed = model(inputs).detach()\n",
    "        b = inputs.data.cpu().numpy()[0].transpose(1,2,0)\n",
    "        a = reconstructed.data.cpu().numpy()[0].transpose(1,2,0)\n",
    "        \n",
    "        diff = np.abs(a - b)\n",
    "        \n",
    "        plt.figure(figsize=(12, 4))\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.imshow(b, cmap='gray', vmin = 0, vmax = 1, interpolation='none')\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.imshow(a, cmap='gray', vmin = 0, vmax = 1, interpolation='none')\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.imshow(diff, interpolation='none')\n",
    "        plt.show()\n",
    "        \n",
    "        if ind == 1:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c2453f-f6a3-4d1d-9472-cc081d63fbd6",
   "metadata": {},
   "source": [
    "## テスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ed53df-0b92-4899-b650-632e485f5b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_test = transforms.Compose([transforms.Resize((128,128)), transforms.ToTensor()])\n",
    "test_bad_data = MVTecAD(image_dir=\"./mvtec_anomaly_detection/capsule/test/good\", transform=transform_test)\n",
    "test_bad_data = MVTecAD(image_dir=\"./mvtec_anomaly_detection/capsule/test/crack\", transform=transform_test)\n",
    "test_loader = torch.utils.data.DataLoader(test_bad_data, batch_size=1, shuffle=False)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for ind, (inputs, _) in enumerate(test_loader):\n",
    "        if use_cuda:\n",
    "            inputs = inputs.cuda()\n",
    "            \n",
    "        reconstructed = model(inputs).detach()\n",
    "        b = inputs.data.cpu().numpy()[0].transpose(1,2,0)\n",
    "        \n",
    "        a = reconstructed.data.cpu().numpy()[0].transpose(1,2,0)\n",
    "        \n",
    "        diff = np.abs(a - b)\n",
    "\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.imshow(b, cmap='gray', vmin = 0, vmax = 1, interpolation='none')\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.imshow(a, cmap='gray', vmin = 0, vmax = 1, interpolation='none')\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.imshow(diff, interpolation='none')\n",
    "        plt.show()\n",
    "        \n",
    "        if ind == 2:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e563bfed-2b9d-4075-af21-eab21695ceda",
   "metadata": {},
   "source": [
    "## 繰り返しによる異常検知"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e804250-1f9e-4748-b8d3-d38611eddfc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iter = 99\n",
    "alpha = 0.5\n",
    "lam = 0.05\n",
    "decay_rate = 0.1\n",
    "minimum = 1e12\n",
    "th = 0.5\n",
    "\n",
    "transform_test = transforms.Compose([transforms.Resize((128, 128)), transforms.ToTensor()])\n",
    "test_bad_data = MVTecAD(image_dir=\"./mvtec_anomaly_detection/capsule/test/crack\", transform=transform_test)\n",
    "test_bad_loader = torch.utils.data.DataLoader(test_bad_data, batch_size=1, shuffle=False)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "loss_func = nn.MSELoss(reduction='sum')\n",
    "if use_cuda:\n",
    "    loss_func = loss_func.cuda()\n",
    "\n",
    "for index, (x_org, _) in enumerate(test_bad_loader):\n",
    "    # 2つ目のサンプルを例として実行するため，1つ目を飛ばして実行\n",
    "    if index == 0:\n",
    "        continue\n",
    "    \n",
    "    img = x_org[0].data.numpy()\n",
    "    \n",
    "    x_t_images = []\n",
    "    grad_images = []\n",
    "    reconstructed_images = []\n",
    "    \n",
    "    if use_cuda:\n",
    "        x_org = x_org.cuda()\n",
    "\n",
    "    x_org.requires_grad_(True)\n",
    "    rec_x = model(x_org).detach()\n",
    "\n",
    "    loss = loss_func(x_org, rec_x)\n",
    "    loss.backward()\n",
    "    grads = x_org.grad.data\n",
    "    x_t = x_org - alpha*grads*(x_org - rec_x)**2\n",
    "    \n",
    "    grad_images.append(grads[0].cpu().numpy().transpose(1,2,0))\n",
    "    reconstructed_images.append(rec_x[0].data.cpu().numpy().transpose(1,2,0))\n",
    "    x_t_images.append(x_t[0].data.cpu().numpy().transpose(1,2,0))\n",
    "\n",
    "    losses = torch.zeros(max_iter)\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        x_t = Variable(x_t.clamp(min=0, max=1), requires_grad=True)\n",
    "        rec_x = model(x_t).detach()\n",
    "        rec_loss = loss_func(x_t, rec_x)\n",
    "        losses[i] = rec_loss.item()\n",
    "\n",
    "        if minimum <= rec_loss and use_decay_lr is True:\n",
    "            minimum = min(minimum, rec_loss)\n",
    "        if rec_loss <= th:\n",
    "            break\n",
    "\n",
    "        l1 = torch.abs(x_t - x_org).sum()\n",
    "        loss = rec_loss + lam*l1\n",
    "        loss.backward()\n",
    "        grads = x_t.grad.data\n",
    "\n",
    "        mask = (x_t - rec_x)**2\n",
    "        energy = grads * mask\n",
    "\n",
    "        x_t = x_t - alpha*energy\n",
    "        \n",
    "        grad_images.append(grads[0].cpu().numpy().transpose(1,2,0))\n",
    "        reconstructed_images.append(rec_x[0].data.cpu().numpy().transpose(1,2,0))\n",
    "        x_t_images.append(x_t[0].data.cpu().numpy().transpose(1,2,0))\n",
    "\n",
    "    plt.imshow(img.transpose(1, 2, 0), vmin = 0, vmax = 1, interpolation='none')\n",
    "    plt.title(\"orig image\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(30, 30))\n",
    "    for i, img in enumerate(x_t_images):\n",
    "        plt.subplot(10, 10, i+1)\n",
    "        plt.imshow(img, vmin = 0, vmax = 1, interpolation='none')\n",
    "    plt.show()\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2231e4dd-8ef3-4f48-ada8-4a486188d438",
   "metadata": {},
   "source": [
    "## 課題\n",
    "\n",
    "1. 反復回数を増加させたときにどのような再構成画像が生成されるか確認しましょう．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4b3ced-9d4b-4e14-81dd-62ca078fb2b6",
   "metadata": {},
   "source": [
    "## 参考文献\n",
    "\n",
    "[1] David Dehaene, Oriel Frigo, Sébastien Combrexelle, Pierre Eline, \"Iterative energy-based projection on a normal data manifold for anomaly localization,\" in ICLR, 2020."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
