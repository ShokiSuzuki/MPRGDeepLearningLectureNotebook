{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/machine-perception-robotics-group/MPRGDeepLearningLectureNotebook/blob/master/12_gan/gan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QMtdu1IbpZL"
      },
      "source": [
        "# Generative Adversarial Networks (GAN)\n",
        "## 目的\n",
        "GANによって画像の生成をして動作を理解する．"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-n2P--PtOHr"
      },
      "source": [
        "## モジュールのインポート\n",
        "\n",
        "はじめに必要となるモジュールをインポートします．\n",
        "\n",
        "### GPUの確認\n",
        "GPUを使用した計算が可能かどうかを確認します．\n",
        "\n",
        "`GPU availability: True`と表示されれば，GPUを使用した計算を行うことが可能です．\n",
        "Falseとなっている場合は，上部のメニューバーの「ランタイム」→「ランタイムのタイプを変更」からハードウェアアクセラレータをGPUにしてください．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uOIgRbOGbpZM"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "import urllib.request\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# GPUの確認\n",
        "use_cuda = torch.cuda.is_available()\n",
        "print('Use CUDA:', use_cuda)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tbo56TMkbpZP"
      },
      "source": [
        "## ネットワークの構築\n",
        "\n",
        "GANは，Generator (生成器)とDiscriminator (識別器)と呼ばれる２つのネットワークによって構成される生成モデルです．\n",
        "そのため，2つのネットワークを別々に構築します．\n",
        "\n",
        "Generatorは，$N(0, 1)$や$U[-1, 1]$からサンプリングした潜在変数を入力して画像を生成するネットワークです．Generatorは，綺麗な画像を生成することでDiscriminatorを欺くことを目的としています．\n",
        "\n",
        "一方で，Discriminatorは実画像 (訓練画像)またはGeneratorが生成した画像のどちらかを入力して，入力されたデータを正確に判別するネットワークです．Discriminatorは，入力画像の中からGeneratorの生成した画像を見破ることを目的としています．\n",
        "\n",
        "GANの最終的な目的は，実画像$x$の確率分布$p_{data}(x)$と実画像$x$をGenerator上の分布で見た時の確率分布$p_{g}(x)$が一致することです．つまり，$p_{data}(x)=p_{g}(x)$が成立した時にDiscriminatorが完全にRealなのかFakeなのかわからなくなっていると言えます．\n",
        "\n",
        "GANのネットワークを簡易的に表現したものを，以下に示します．Generator及びDiscriminatorの構造は非常にシンプルで，全結合とReLUによって構築します．\n",
        "\n",
        "<img src=\"https://dl.dropboxusercontent.com/s/deek34es6dqu4lb/gan.png\" width=50%>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OXQrlp9UbpZP"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, latent_dim=100):\n",
        "        super(Generator, self).__init__()\n",
        "        self.layer = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(256, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(512, 784))\n",
        "        \n",
        "    def forward(self, z):\n",
        "        return self.layer(z)\n",
        "    \n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.layer = nn.Sequential(\n",
        "            nn.Linear(784, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(256, 1))\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return self.layer(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRtlFoWxbpZR"
      },
      "source": [
        "## データセットと最適化関数\n",
        "データセットにはMNISTを使用します．\n",
        "最適化関数はAdam optimizer使用し，学習率$2\\times 10^4$，betaの値を$0.5, 0.999$として学習します．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "muwbLKFzbpZS"
      },
      "outputs": [],
      "source": [
        "# MNIST datasetの設定\n",
        "transform_train = transforms.Compose([transforms.ToTensor()])\n",
        "mnist_data = datasets.MNIST(root='./data', train=True, transform=transform_train, download=True)\n",
        "training_data = DataLoader(mnist_data, batch_size=100, shuffle=True)\n",
        "\n",
        "latent_dim = 100\n",
        "G = Generator(latent_dim=latent_dim)\n",
        "D = Discriminator()\n",
        "if use_cuda:\n",
        "    G = G.cuda()\n",
        "    D = D.cuda()\n",
        "opt_g = optim.Adam(G.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "opt_d = optim.Adam(D.parameters(), lr=0.0002, betas=(0.5, 0.999))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VuiMK-hUbpZU"
      },
      "source": [
        "## GANの学習\n",
        "\n",
        "次に，GANの学習をします．\n",
        "\n",
        "GANの最適化式は以下に示す通りです．\n",
        "\n",
        "$$\n",
        "\\min_{G}\\max_{D}V(D, G) = \\mathbb{E}_{x\\sim P_{data}(x)}\\left[\\log\\left(D(x)\\right)\\right] + \\mathbb{E}_{z\\sim P(z)}\\left[\\log\\left(1 - D(\\hat{x})\\right)\\right]\n",
        "$$\n",
        "\n",
        "ここで，$x$は実画像，$\\hat{x}$がGeneratorの生成した画像G(z)に対応します．GANを学習する際は，binary cross entopyを用いて，実画像は1に，生成画像は0に近似するように学習をします．\n",
        "Discriminatorは，実画像は1生成画像は0と識別するとように学習をしますが，Generatorは生成した画像を実画像であるとDiscriminatorに誤識別をさせたいので，1と識別されるように学習をします．\n",
        "これによりGANにおける敵対学習を行うことができます．\n",
        "\n",
        "`n_critic`は，Discriminatorを1 iterationあたり何回更新するかを制御する数となっています．\n",
        "すなわち，Discriminatorを複数回更新した後にGeneratorを1回更新します．\n",
        "この理由は，モード崩壊を防止するためです．モード崩壊とは，GANの学習における一般的な問題で，Generatorがある一定の画像しか生成できなることや全く画像が生成できなくなる問題を指します．\n",
        "\n",
        "Discriminatorは，精度が高すぎても低すぎても学習が失敗してしまうため，適切なn_criticを指定する必要があります．n_criticが多いと簡単にモード崩壊します．一般的には，2回程度がよく用いられます．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fan3aF6zbpZU"
      },
      "outputs": [],
      "source": [
        "n_epoch = 10\n",
        "n_critic = 2\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "for epoch in range(1, n_epoch+1):\n",
        "    Tensor = torch.cuda.FloatTensor\n",
        "    for idx, (real_x, _) in enumerate(training_data):\n",
        "        real_x = real_x.cuda()\n",
        "        batch = real_x.size(0)\n",
        "        flag_real = Tensor(batch, 1).fill_(1.0)\n",
        "        flag_fake = Tensor(batch, 1).fill_(0.0)\n",
        "        \n",
        "        for _ in range(n_critic):\n",
        "            D.zero_grad()\n",
        "\n",
        "            z = torch.randn(batch, latent_dim)\n",
        "            if use_cuda:\n",
        "                z = z.cuda()\n",
        "            \n",
        "            fake_x = G(z)\n",
        "            out_real = D(real_x.view(batch, -1))\n",
        "            out_fake = D(fake_x.detach().view(batch, -1))\n",
        "            loss_real = criterion(out_real, flag_real)\n",
        "            loss_fake = criterion(out_fake, flag_fake)\n",
        "            dis_loss = loss_real + loss_fake\n",
        "            dis_loss.backward()\n",
        "            opt_d.step()\n",
        "            \n",
        "        G.zero_grad()\n",
        "\n",
        "        z = torch.randn(batch, latent_dim)\n",
        "        if use_cuda:\n",
        "            z = z.cuda()\n",
        "\n",
        "        fake_x = G(z)\n",
        "        out_gen = D(fake_x)\n",
        "        gen_loss = criterion(out_gen, flag_real)\n",
        "        gen_loss.backward()\n",
        "        opt_g.step()\n",
        "        \n",
        "        if idx % 100 == 0:\n",
        "            print('Training epoch: {} [{}/{} ({:.0f}%)] | D loss: {:.6f} | G loss: {:.6f} |'\\\n",
        "                  .format(epoch, idx * len(real_x), len(training_data.dataset),\n",
        "                  100. * idx / len(training_data), dis_loss.item(), gen_loss.item()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvfYDd_0H-lT"
      },
      "source": [
        "## 学習したGeneratorによる画像生成\n",
        "\n",
        "学習したGeneratorを用いて画像を生成します．\n",
        "\n",
        "ここでは，正規分布に従い乱数`z`を生成し，それをGeneratorへと入力することで，画像生成をおこない，その結果を表示します．\n",
        "\n",
        "適切な学習が行われている場合は，0~9の数字の画像が生成されます．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S5WW2f9HbpZX"
      },
      "outputs": [],
      "source": [
        "num_generate = 100\n",
        "ch = 100\n",
        "z = torch.randn(num_generate, ch)\n",
        "if use_cuda:\n",
        "    z = z.cuda()\n",
        "test_img = G(z)\n",
        "\n",
        "if use_cuda:\n",
        "    test_img = test_img.cpu()\n",
        "test_img_array = (test_img * 256.).clamp(min=0., max=255.).view(num_generate, 28, 28).data.numpy()\n",
        "\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "for i, im in enumerate(test_img_array):\n",
        "    ax = fig.add_subplot(10, 10, i+1, xticks=[], yticks=[])\n",
        "    ax.imshow(im, 'gray')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWzsGnZxJYkg"
      },
      "source": [
        "# 課題\n",
        "\n",
        "1. 潜在変数の次元数を100次元から減らした場合どうなるでしょうか．また，増やした場合はどのようになるでしょうか．"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3jn_GNko7JP"
      },
      "source": [
        "# 参考文献\n",
        "[1] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville and Yoshua Bengio, Generative adversarial nets, NIPS, 2014."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "02_GAN.ipynb",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}