{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/machine-perception-robotics-group/MPRGDeepLearningLectureNotebook/blob/master/13_rnn/01_03_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6ODOW0pVTXD"
      },
      "source": [
        "# RNN (LSTM, GRU) による電力予測\n",
        "\n",
        "---\n",
        "\n",
        "## 目的\n",
        "リカレントニューラルネットワークを使って電力予測を行います．\n",
        "ここでは，Recurrent Neural Network（RNN）を使用します．\n",
        "\n",
        "## リカレントニューラルネットワーク\n",
        "リカレントニューラルネットワークは，系列データを扱うことができるニューラルネットワークです． 例えば，「今日は良い天気です」という文章において，「今日は」，「良い」という時系列データを与えると，次に現れる単語として「天気」を予測するという問題です． リカレントニューラルネットワークを利用することで，過去の系列情報から文脈の流れを考慮した予測ができるようになります． 応用例として，３０分後の電力を予測する，翌日の株価を予測するなどの予測モデル，音声認識や機械翻訳などがあります．"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6ENdskSVaqw"
      },
      "source": [
        "##リカレントニューラルネットワークの種類\n",
        "リカレントニューラルネットワークにはいくつかの種類があります．\n",
        "\n",
        "* Elman Network：一般的なリカレントニューラルネットワーク．１時刻前の情報を内部状態として，現時刻の入力と合わせて中間層に与える\n",
        "* Jordan Network：１時刻前の出力層の情報を現時刻の入力と合わせて中間層に与える\n",
        "* Echo state network (ESN)：一部の重みを乱数で初期化し，更新しない．中間層内のユニットは相互結合する\n",
        "* Long Short-Term Memory (LSTM)：内部情報を記憶するメモリセルを持ち，複数のゲートによってメモリセルの情報を書き換えたり出力したりする\n",
        "* Gated Recurrent Unit (GRU)：内部情報の保持方法をLSTMよりもシンプルな構造にしたリカレントニューラルネットワーク \n",
        "* Bidirectional RNN：過去の情報だけでなく，未来の情報も利用する双方向のリカレントニューラルネットワーク\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMeg988hVjyB"
      },
      "source": [
        "## Elman Network\n",
        "リカレントニューラルネットワークは，普通のニューラルネットワークと同様に，入力層，中間層，出力層から構成されます．大きな違いは，中間層の出力が中間層の入力につながっている点です．具体的には，1時刻前の中間層の出力が次の時刻の中間層に入力されます．これにより，過去の情報を伝搬することができ，過去を考慮した出力が可能です．\n",
        "\n",
        "\n",
        "<img src=\"https://github.com/himidev/Lecture/blob/main/13_rnn/01_03_RNN/RNN.png?raw=true\" width = 80%>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4U-Ta4SHVj0M"
      },
      "source": [
        "##リカレントニューラルネットワークの学習\n",
        "リカレントニューラルネットワークは，時系列データを逐次与えます．この流れを展開すると\n",
        "ニューラルネットワークを時間方向につなげた大きなネットワークとみなすことができます．\n",
        "そのため，リカレントニューラルネットワークの学習にもニューラルネットワークと同様に誤差逆伝播法を用いることができます．\n",
        "リカレントニューラルネットワークでの誤差逆伝播法は， Back-propagation through time (BPTT)法と呼ばれています．\n",
        "\n",
        "まず，図の黒矢印に従い，系列データを時刻$t=0$から順伝播します．\n",
        "ネットワークは時刻ごとに別々にあるのではなく，１つのネットワークに対して逐次データを入力します．\n",
        "その時，各時刻における各層の値は変わっていくので，それらを記憶しておきます．\n",
        "また，順伝播時に各時刻における誤差を算出しておきます．\n",
        "誤差関数には，平均二乗誤差関数を利用することが多いです．\n",
        "\n",
        "時刻t=Tまで系列データの順伝播が終わると学習開始となります．\n",
        "学習は，ニューラルネットワークの誤差逆伝播法と同様に，BPTTでも誤差の勾配を求めて結合重みを更新します．\n",
        "その際，時刻をさかのぼるように，時刻t=Tの出力層から始めます．\n",
        "学習では，以下の３箇所の結合重みを順番に更新します．\n",
        "* 時刻tの出力層から時刻tの中間層間の結合重み\n",
        "* 時刻tの中間層から時刻t-1の中間層間の結合重み\n",
        "* 時刻tの中間層から時刻tの入力層間の結合重み\n",
        "\n",
        "<img src=\"https://github.com/himidev/Lecture/blob/main/13_rnn/01_03_RNN/back.png?raw=true\" width = 70%>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8E9WwLkWKWj"
      },
      "source": [
        "## 勾配消失問題\n",
        "リカレントニューラルネットワークは，系列データの文脈を捉えて推定を行うことができます．\n",
        "この時，系列の長さに関係なく，系列データの文脈を反映せることが重要です．\n",
        "すなわち，時刻tから離れた遠い過去の時刻のデータを時刻tの出力に反映しなければなりません．\n",
        "しかし，リカレントニューラルネットワークを時間方向に展開すると深いニューラルネットワークと\n",
        "みなすことができ，誤差逆伝播時に誤差が入力に近い階層まで伝播させることが困難です．\n",
        "系列データが長い場合，リカレントニューラルネットワークでも勾配消失問題が生じます．\n",
        "したがって，リカレントニューラルネットワークでは，10時刻程度のデータが限界となることが多いです．\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyU9p5x7WOTL"
      },
      "source": [
        "## Long Short Term Memory(LSTM)\n",
        "LSTMは，リカレントニューラルネットワークと同様に，時系列データを扱うニューラルネットモデルです．\n",
        "リカレントニューラルネットワークは，系列データにおける過去のデータを考慮することができますが，\n",
        "10時刻程度しか考慮できませんでした．\n",
        "LSTMは，内部状態を記憶するメモリセルと３つのゲートで構成されています．\n",
        "３つのゲートは，メモリセルの値が次時刻でどれだけ保持されるかを調節する忘却ゲート，メモリセルに加算される値を調節する入力ゲート，\n",
        "メモリセルの値が次の層にどれだけ影響を及ぼすかを調節する出力ゲートです．\n",
        "このような特徴を持つメモリセルと３つのゲートを駆使して，勾配消失問題を解決し，短期と長期の記憶を両立した内部情報の保持方法を実現しています．\n",
        "ここで，σはシグモイド関数，tanhはハイパボリックタンジェント関数です．\n",
        "忘却ゲートは赤線，入力ゲートは緑線，出力ゲートは青線に沿って処理をします．\n",
        "\n",
        "\n",
        "<img src=\"https://github.com/himidev/Lecture/blob/main/13_rnn/01_03_RNN/LSTM.png?raw=true\" width = 50%>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZel4bGXWOWI"
      },
      "source": [
        "## Gated Reccurent Unit (GRU)\n",
        "LSTMは非常に複雑な構造ですが，長期と短期の記憶の両立ができる特徴があります．\n",
        "同様の特徴をよりシンプルな構造で実現した方法がGated Recurrent Unit (GRU)です．\n",
        "GRUは，図ような構造をしています．\n",
        "LSTMとの大きな違いはメモリセルがないことです．\n",
        "また，LSTMでは，３種類のゲートがありましたが，GRUではリセットゲートと更新ゲートの２種類のゲートとなります．\n",
        "リセットゲートは，入力と前時刻の中間層の値から求めます．\n",
        "活性化関数にはシグモイド関数を用います．\n",
        "\n",
        "<img src=\"https://github.com/himidev/Lecture/blob/main/13_rnn/01_03_RNN/GRU.png?raw=true\" width = 50%>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NeMvLBptWY4l"
      },
      "source": [
        "##データのダウンロード\n",
        "プログラムの動作に必要なデータをダウンロードし，zipファイルを解凍します．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MPNQu0HnVKXV"
      },
      "outputs": [],
      "source": [
        "!wget -q http://www.mprg.cs.chubu.ac.jp/tutorial/ML_Lecture/SOLAR/data.zip\n",
        "!unzip -q data.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8AR0OxdEXa7T"
      },
      "source": [
        "データを確認してみます．最初の７つの値が曜日のone-hot vector，次の２４個の値は時間のone-hot vector，残りが電力，気温，湿度です．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzqp8pngXlUC",
        "outputId": "4f263ed8-b2bf-4200-8c14-4a35e7f90326"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "!ls data/train\n",
        "tmp_data = np.load(\"./data/train/BEMS_RNN_train_data.npy\")\n",
        "print(tmp_data[0])\n",
        "print(tmp_data.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-P-vK8-Xecl"
      },
      "source": [
        "## モジュールのインポート\n",
        "はじめに必要なモジュールをインポートします．\n",
        "\n",
        "\n",
        "### GPUの確認\n",
        "GPUを使用した計算が可能かどうかを確認します．\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H82XmLCBXnrb",
        "outputId": "712dcea0-d83d-492d-9995-90554d6fa3d5"
      },
      "outputs": [],
      "source": [
        "from time import time\n",
        "from os import path\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# GPUの確認\n",
        "use_cuda = torch.cuda.is_available()\n",
        "print('Use CUDA:', use_cuda)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKNB7rvIZ_Ml"
      },
      "source": [
        "## データセットオブジェクトの作成\n",
        "\n",
        "電力データセットに対する，PyTorchのデータセットオブジェクト (`torch.utils.data.Dataset`) を作成します．\n",
        "`Dataset`は，指定したデータセットを読み込み，学習やテストのためにデータを準備し生成するためのクラスです．\n",
        "これまでの実習で使用したMNISTやCIFARデータセットはPyTorch (torchvision) 内に準備されているデータセットオブジェクトでした．\n",
        "今回用いるデータセットは，torchvisonには存在しないため，自身で定義を行います．\n",
        "\n",
        "まず，`__init__`関数により，必要なデータを読み込みます．\n",
        "この時，`__init__`関数の引数を指定します．\n",
        "`root`は読み込むデータセットを配置しているディレクトリ，`train`は学習またはテストデータのどちらを扱うかを指定する変数，`delay`は入力された情報の何時刻後を正解として用意するかを指定する変数，`time_window`は1サンプルあたり何時刻のデータを準備するかをしてする変数です．\n",
        "\n",
        "まず，`root`および`train`変数から，学習またはテストデータを読み込みます．\n",
        "その後，`delay`で指定した時刻を元に正解データを準備します．\n",
        "最後に，`time_window`で指定した時間窓で1サンプルとなるように，データを作成し，`self.data`および`self.label`にデータを格納します．\n",
        "これにより，`self.data`，`self.label`に入力データおよび正解データを格納します．\n",
        "\n",
        "`__getitem__`関数で，指定したインデックス（`item`）のデータを取り出し，返します．\n",
        "\n",
        "`__len__`関数は，このデータセットが保有するサンプル数を返すように定義を行います．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ubF1_8DhaC5K"
      },
      "outputs": [],
      "source": [
        "class BEMSDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, root=\"./data\", train=True, delay=1, time_window=10):\n",
        "        super().__init__()\n",
        "        self.root = root\n",
        "        self.train = train\n",
        "        self.delay = delay\n",
        "        self.time_window = time_window\n",
        "\n",
        "        # データの読み込み\n",
        "        if self.train:\n",
        "            data_src = np.load(path.join(self.root, 'train', 'BEMS_RNN_train_data.npy'))\n",
        "            label_src = np.load(path.join(self.root, 'train', 'BEMS_RNN_train_labels.npy'))\n",
        "        else:\n",
        "            data_src  = np.load(path.join(self.root, 'test', 'BEMS_RNN_test_data.npy'))\n",
        "            label_src = np.load(path.join(self.root, 'test', 'BEMS_RNN_test_labels.npy'))\n",
        "\n",
        "        data_src = np.asarray(data_src[:-self.delay])\n",
        "        label_src = np.asarray(label_src[self.delay:])\n",
        "\n",
        "        self.data = []\n",
        "        self.label = []\n",
        "        for frame_i in range(len(data_src) - self.time_window):\n",
        "            self.data.append(data_src[frame_i:frame_i+self.time_window])\n",
        "            self.label.append(label_src[frame_i:frame_i+self.time_window])\n",
        "\n",
        "        self.data = np.asarray(self.data)\n",
        "        self.label = np.asarray(self.label)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        d = self.data[item, :]\n",
        "        l = self.label[item, :]\n",
        "        return d, l\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data.shape[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-0d6emJaFWQ"
      },
      "source": [
        "## ネットワークモデルの定義\n",
        "リカレントニューラルネットワークを定義します．\n",
        "ここでは，RNN層1層，全結合層1層から構成されるネットワークとします．\n",
        "\n",
        "`forward`関数では，定義した層を接続して処理するように記述し，最終的な出力結果を求めます．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vdCVwOGBaHaz"
      },
      "outputs": [],
      "source": [
        "class RNN_Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(RNN_Net, self).__init__()\n",
        "        self.rnn = nn.RNNCell(34, 128)\n",
        "        self.l1 = nn.Linear(128, 1)\n",
        "    \n",
        "    def forward(self, x, hx):\n",
        "        hx = self.rnn(x, hx)\n",
        "        h = self.l1(hx)\n",
        "        return h, hx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5eOqpBZaKGA"
      },
      "source": [
        "## ネットワークの作成\n",
        "上のプログラムで定義したネットワークを作成します．\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43ToDcxsaPGq"
      },
      "outputs": [],
      "source": [
        "model = RNN_Net()\n",
        "if use_cuda:\n",
        "    model.cuda()\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQw0QicKaRAE"
      },
      "source": [
        "## 学習\n",
        "先ほど定義したデータセットと作成したネットワークを用いて，学習を行います．\n",
        "\n",
        "1回の誤差を算出するデータ数（ミニバッチサイズ）を100，学習エポック数を20とします．\n",
        "また，1サンプルあたりのデータの長さ（time window）を10に指定します．\n",
        "\n",
        "次にデータローダーを定義します．\n",
        "データローダーでは，上で読み込んだデータセット（`train_data`）を用いて，for文で指定したミニバッチサイズでデータを読み込むオブジェクトを作成します．\n",
        "この時，`shuffle=True`と設定することで，読み込むデータを毎回ランダムに指定します．\n",
        "\n",
        "次に，誤差関数を設定します．\n",
        "今回は，連続値を出力する回帰問題をあつかうため，`MSELoss`を`criterion`として定義します．\n",
        "\n",
        "学習を開始します．\n",
        "\n",
        "各更新において，学習用データと教師データをそれぞれ`data`と`label`とします．\n",
        "まず，LSTMの隠れ状態とセル状態である`hx`と`cx`を`torch.zeros`を用いて初期化します．\n",
        "この時，1次元目のサイズはバッチサイズに対応するように，`data`のサイズから自動的に決定します．\n",
        "\n",
        "その後，学習モデルに`data`を与えて各クラスの確率yを取得します．\n",
        "今回はLSTMを用いて時系列データを順次処理するため，for文を用いて，各時刻のデータを順番に入力し，結果を得ます．\n",
        "そして，各クラスの確率yと教師ラベルtとの誤差を`criterion`で算出します．\n",
        "また，認識精度も算出します．\n",
        "そして，誤差をbackward関数で逆伝播し，ネットワークの更新を行います．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFBfkbt5aTEa",
        "outputId": "af70e942-1f0b-4394-9544-fdebf4a461be"
      },
      "outputs": [],
      "source": [
        "# ミニバッチサイズ・エポック数の設定\n",
        "batch_size = 100\n",
        "epoch_num = 20\n",
        "time_window = 10\n",
        "\n",
        "# データセットの読み込み・データローダーの設定\n",
        "train_data = BEMSDataset(root=\"./data\", train=True, delay=1, time_window=time_window)\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# 誤差関数の設定\n",
        "criterion = nn.MSELoss()\n",
        "if use_cuda:\n",
        "    criterion.cuda()\n",
        "\n",
        "# ネットワークを学習モードへ変更\n",
        "model.train()\n",
        "\n",
        "start = time()\n",
        "for epoch in range(1, epoch_num+1):\n",
        "    total_loss = 0\n",
        "\n",
        "    for data, label in train_loader:\n",
        "        hx = torch.zeros(data.size()[1], 128)\n",
        "        \n",
        "        if use_cuda:\n",
        "            data = data.cuda()\n",
        "            label = label.cuda()\n",
        "            hx = hx.cuda()\n",
        "    \n",
        "        accum_loss = 0.0\n",
        "        \n",
        "        for idx_window in range(time_window):\n",
        "            y, hx = model(data[idx_window], hx)\n",
        "            loss = criterion(y, label[idx_window])\n",
        "            accum_loss += loss\n",
        "            total_loss += loss.item()\n",
        "            \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "  \n",
        "    elapsed_time = time() - start\n",
        "    print(\"epoch: {}, mean loss: {}, elapsed_time: {}\".format(epoch, total_loss, elapsed_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDF2IlzvaUtE"
      },
      "source": [
        "## 評価\n",
        "学習したネットワークモデルを用いて評価（予測結果の可視化）を行います．\n",
        "可視化にはmatplotlibを用います"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "ixaVijMUaWei",
        "outputId": "935cf040-b7a8-4eda-cc81-ada998fabd1b"
      },
      "outputs": [],
      "source": [
        "# データセットの読み込み・データローダーの設定\n",
        "test_data = BEMSDataset(root=\"./data\", train=False, delay=1, time_window=1)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=1, shuffle=False)\n",
        "\n",
        "# ネットワークを評価モードへ変更\n",
        "model.eval()\n",
        "\n",
        "prediction_result = []\n",
        "        \n",
        "# 評価の実行\n",
        "hx = torch.zeros(1, 128)\n",
        "if use_cuda:\n",
        "    hx = hx.cuda()\n",
        "    \n",
        "with torch.no_grad():\n",
        "    for data, label in test_loader:\n",
        "        \n",
        "        if use_cuda:\n",
        "            data = data.cuda()\n",
        "\n",
        "        y, hx = model(data[0], hx)\n",
        "        \n",
        "        prediction_result.append(y.item())\n",
        "\n",
        "prediction_result = np.array(prediction_result).flatten()\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "mse = mean_squared_error(prediction_result, test_data.label)\n",
        "print(\"mse error : {:.4f}\".format(mse))\n",
        "\n",
        "\n",
        "# 結果の表示\n",
        "plt.figure()\n",
        "plt.plot(test_data.label, color='red', label='true')\n",
        "plt.plot(prediction_result.tolist(), color='blue', label='pred')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdZl17-naZd9"
      },
      "source": [
        "## LSTMによる学習と評価\n",
        "次に，LSTMを利用します．\n",
        "LSTM層はRecurrent Neural Networkの一種です．\n",
        "LSTMへの入力サイズはNoneとし，データにより変更できるようにしておきます．\n",
        "\n",
        "`forward`関数では，定義した層を接続して処理するように記述します．\n",
        "LSTMをはじめとするRecurrent Neural Networkでは，内部に過去の入力情報から計算した値を保持しています．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lUB_3YiRaa47"
      },
      "outputs": [],
      "source": [
        "class LSTM_Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LSTM_Net, self).__init__()\n",
        "        self.lstm = nn.LSTMCell(34, 128)\n",
        "        self.l1 = nn.Linear(128, 1)\n",
        "    \n",
        "    def forward(self, x, hx, cx):\n",
        "        hx, cx = self.lstm(x, (hx, cx))\n",
        "        h = self.l1(hx)\n",
        "        return h, hx, cx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "GX2SwWzoad0i",
        "outputId": "015a7110-89be-4e2a-d874-f7a7041f7ec5"
      },
      "outputs": [],
      "source": [
        "model = LSTM_Net()\n",
        "if use_cuda:\n",
        "    model.cuda()\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "# ミニバッチサイズ・エポック数の設定\n",
        "batch_size = 100\n",
        "epoch_num = 20\n",
        "time_window = 10\n",
        "\n",
        "# データセットの読み込み・データローダーの設定\n",
        "train_data = BEMSDataset(root=\"./data\", train=True, delay=1, time_window=time_window)\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# 誤差関数の設定\n",
        "criterion = nn.MSELoss()\n",
        "if use_cuda:\n",
        "    criterion.cuda()\n",
        "\n",
        "# ネットワークを学習モードへ変更\n",
        "model.train()\n",
        "\n",
        "start = time()\n",
        "for epoch in range(1, epoch_num+1):\n",
        "    total_loss = 0\n",
        "\n",
        "    for data, label in train_loader:\n",
        "        hx = torch.zeros(data.size()[1], 128)\n",
        "        cx = torch.zeros(data.size()[1], 128)\n",
        "        \n",
        "        if use_cuda:\n",
        "            data = data.cuda()\n",
        "            label = label.cuda()\n",
        "            hx = hx.cuda()\n",
        "            cx = cx.cuda()\n",
        "    \n",
        "        accum_loss = 0.0\n",
        "        \n",
        "        for idx_window in range(time_window):\n",
        "            y, hx, cx = model(data[idx_window], hx, cx)\n",
        "            loss = criterion(y, label[idx_window])\n",
        "            accum_loss += loss\n",
        "            total_loss += loss.item()\n",
        "            \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "  \n",
        "    elapsed_time = time() - start\n",
        "    print(\"epoch: {}, mean loss: {}, elapsed_time: {}\".format(epoch, total_loss, elapsed_time))\n",
        "\n",
        "\n",
        "# データセットの読み込み・データローダーの設定\n",
        "test_data = BEMSDataset(root=\"./data\", train=False, delay=1, time_window=1)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=1, shuffle=False)\n",
        "\n",
        "# ネットワークを評価モードへ変更\n",
        "model.eval()\n",
        "\n",
        "prediction_result = []\n",
        "        \n",
        "# 評価の実行\n",
        "hx = torch.zeros(1, 128)\n",
        "cx = torch.zeros(1, 128)\n",
        "if use_cuda:\n",
        "    hx = hx.cuda()\n",
        "    cx = cx.cuda()\n",
        "    \n",
        "with torch.no_grad():\n",
        "    for data, label in test_loader:\n",
        "        \n",
        "        if use_cuda:\n",
        "            data = data.cuda()\n",
        "\n",
        "        y, hx, cx = model(data[0], hx, cx)\n",
        "        \n",
        "        prediction_result.append(y.item())\n",
        "\n",
        "prediction_result = np.array(prediction_result).flatten()\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "mse = mean_squared_error(prediction_result, test_data.label)\n",
        "print(\"mse error : {:.4f}\".format(mse))\n",
        "\n",
        "\n",
        "# 結果の表示\n",
        "plt.figure()\n",
        "plt.plot(test_data.label, color='red', label='true')\n",
        "plt.plot(prediction_result.tolist(), color='blue', label='pred')\n",
        "plt.legend()\n",
        "plt.show()    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRccRuicagDN"
      },
      "source": [
        "## GRUによる学習と評価\n",
        " 次に，GRUも同様に実験してみます"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IfQ-dRPpah8S"
      },
      "outputs": [],
      "source": [
        "class GRU_Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(GRU_Net, self).__init__()\n",
        "        self.gru = nn.GRUCell(34, 128)\n",
        "        self.l1 = nn.Linear(128, 1)\n",
        "    \n",
        "    def forward(self, x, hx):\n",
        "        hx = self.gru(x, hx)\n",
        "        h = self.l1(hx)\n",
        "        return h, hx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "oP0mOR7GakDn",
        "outputId": "f6c001e6-6b36-4cfa-cc50-57e4b97104f4"
      },
      "outputs": [],
      "source": [
        "model = GRU_Net()\n",
        "if use_cuda:\n",
        "    model.cuda()\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "# ミニバッチサイズ・エポック数の設定\n",
        "batch_size = 100\n",
        "epoch_num = 20\n",
        "time_window = 10\n",
        "\n",
        "# データセットの読み込み・データローダーの設定\n",
        "train_data = BEMSDataset(root=\"./data\", train=True, delay=1, time_window=time_window)\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# 誤差関数の設定\n",
        "criterion = nn.MSELoss()\n",
        "if use_cuda:\n",
        "    criterion.cuda()\n",
        "\n",
        "# ネットワークを学習モードへ変更\n",
        "model.train()\n",
        "\n",
        "start = time()\n",
        "for epoch in range(1, epoch_num+1):\n",
        "    total_loss = 0\n",
        "\n",
        "    for data, label in train_loader:\n",
        "        hx = torch.zeros(data.size()[1], 128)\n",
        "        \n",
        "        if use_cuda:\n",
        "            data = data.cuda()\n",
        "            label = label.cuda()\n",
        "            hx = hx.cuda()\n",
        "    \n",
        "        accum_loss = 0.0\n",
        "        \n",
        "        for idx_window in range(time_window):\n",
        "            y, hx = model(data[idx_window], hx)\n",
        "            loss = criterion(y, label[idx_window])\n",
        "            accum_loss += loss\n",
        "            total_loss += loss.item()\n",
        "            \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "  \n",
        "    elapsed_time = time() - start\n",
        "    print(\"epoch: {}, mean loss: {}, elapsed_time: {}\".format(epoch, total_loss, elapsed_time))\n",
        "\n",
        "# データセットの読み込み・データローダーの設定\n",
        "test_data = BEMSDataset(root=\"./data\", train=False, delay=1, time_window=1)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=1, shuffle=False)\n",
        "\n",
        "# ネットワークを評価モードへ変更\n",
        "model.eval()\n",
        "\n",
        "prediction_result = []\n",
        "        \n",
        "# 評価の実行\n",
        "hx = torch.zeros(1, 128)\n",
        "if use_cuda:\n",
        "    hx = hx.cuda()\n",
        "    \n",
        "with torch.no_grad():\n",
        "    for data, label in test_loader:\n",
        "        \n",
        "        if use_cuda:\n",
        "            data = data.cuda()\n",
        "\n",
        "        y, hx = model(data[0], hx)\n",
        "        \n",
        "        prediction_result.append(y.item())\n",
        "\n",
        "prediction_result = np.array(prediction_result).flatten()\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "mse = mean_squared_error(prediction_result, test_data.label)\n",
        "print(\"mse error : {:.4f}\".format(mse))\n",
        "\n",
        "# 結果の表示\n",
        "plt.figure()\n",
        "plt.plot(test_data.label, color='red', label='true')\n",
        "plt.plot(prediction_result.tolist(), color='blue', label='pred')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ia8zuzsGarYu"
      },
      "source": [
        "## RNN 2層のネットワークモデル"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i7G3rarJaro6"
      },
      "outputs": [],
      "source": [
        "class RNN_Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(RNN_Net, self).__init__()\n",
        "        self.rnn1 = nn.RNNCell(34, 128)\n",
        "        self.rnn2 = nn.RNNCell(128, 128)\n",
        "        self.l1 = nn.Linear(128, 1)\n",
        "    \n",
        "    def forward(self, x, hx1, hx2):\n",
        "        h1 = self.rnn1(x, hx1)\n",
        "        h2 = self.rnn2(h1, hx2)\n",
        "        h = self.l1(h2)\n",
        "        return h, h1, h2\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "1veXjZmeas3k",
        "outputId": "cba86fea-e028-40e5-903f-ccb65deeda64"
      },
      "outputs": [],
      "source": [
        "model = RNN_Net()\n",
        "if use_cuda:\n",
        "    model.cuda()\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "# ミニバッチサイズ・エポック数の設定\n",
        "batch_size = 100\n",
        "epoch_num = 20\n",
        "time_window = 10\n",
        "\n",
        "# データセットの読み込み・データローダーの設定\n",
        "train_data = BEMSDataset(root=\"./data\", train=True, delay=1, time_window=time_window)\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# 誤差関数の設定\n",
        "criterion = nn.MSELoss()\n",
        "if use_cuda:\n",
        "    criterion.cuda()\n",
        "\n",
        "# ネットワークを学習モードへ変更\n",
        "model.train()\n",
        "\n",
        "start = time()\n",
        "for epoch in range(1, epoch_num+1):\n",
        "    total_loss = 0\n",
        "\n",
        "    for data, label in train_loader:\n",
        "        hx1 = torch.zeros(data.size()[1], 128)\n",
        "        hx2 = torch.zeros(data.size()[1], 128)\n",
        "        \n",
        "        if use_cuda:\n",
        "            data = data.cuda()\n",
        "            label = label.cuda()\n",
        "            hx1 = hx1.cuda()\n",
        "            hx2 = hx2.cuda()\n",
        "    \n",
        "        accum_loss = 0.0\n",
        "        \n",
        "        for idx_window in range(time_window):\n",
        "            y, hx1, hx2 = model(data[idx_window], hx1, hx2)\n",
        "            loss = criterion(y, label[idx_window])\n",
        "            accum_loss += loss\n",
        "            total_loss += loss.item()\n",
        "            \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "  \n",
        "    elapsed_time = time() - start\n",
        "    print(\"epoch: {}, mean loss: {}, elapsed_time: {}\".format(epoch, total_loss, elapsed_time))\n",
        "\n",
        "# データセットの読み込み・データローダーの設定\n",
        "test_data = BEMSDataset(root=\"./data\", train=False, delay=1, time_window=1)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=1, shuffle=False)\n",
        "\n",
        "# ネットワークを評価モードへ変更\n",
        "model.eval()\n",
        "\n",
        "prediction_result = []\n",
        "        \n",
        "# 評価の実行\n",
        "hx1 = torch.zeros(1, 128)\n",
        "hx2 = torch.zeros(1, 128)\n",
        "if use_cuda:\n",
        "    hx1 = hx1.cuda()\n",
        "    hx2 = hx2.cuda()\n",
        "    \n",
        "with torch.no_grad():\n",
        "    for data, label in test_loader:\n",
        "        \n",
        "        if use_cuda:\n",
        "            data = data.cuda()\n",
        "\n",
        "        y, hx1, hx2 = model(data[0], hx1, hx2)\n",
        "        \n",
        "        prediction_result.append(y.item())\n",
        "\n",
        "prediction_result = np.array(prediction_result).flatten()\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "mse = mean_squared_error(prediction_result, test_data.label)\n",
        "print(\"mse error : {:.4f}\".format(mse))\n",
        "\n",
        "# 結果の表示\n",
        "plt.figure()\n",
        "plt.plot(test_data.label, color='red', label='true')\n",
        "plt.plot(prediction_result.tolist(), color='blue', label='pred')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ro-rZoZauif"
      },
      "source": [
        "##10時刻未来を予測する"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "5ZQEGWD0aweC",
        "outputId": "7770dd03-7492-4f46-93e6-d1b45b377404"
      },
      "outputs": [],
      "source": [
        "model = RNN_Net()\n",
        "if use_cuda:\n",
        "    model.cuda()\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "# ミニバッチサイズ・エポック数の設定\n",
        "batch_size = 100\n",
        "epoch_num = 20\n",
        "time_window = 10\n",
        "\n",
        "# データセットの読み込み・データローダーの設定\n",
        "train_data = BEMSDataset(root=\"./data\", train=True, delay=10, time_window=time_window)\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# 誤差関数の設定\n",
        "criterion = nn.MSELoss()\n",
        "if use_cuda:\n",
        "    criterion.cuda()\n",
        "\n",
        "# ネットワークを学習モードへ変更\n",
        "model.train()\n",
        "\n",
        "start = time()\n",
        "for epoch in range(1, epoch_num+1):\n",
        "    total_loss = 0\n",
        "\n",
        "    for data, label in train_loader:\n",
        "        hx1 = torch.zeros(data.size()[1], 128)\n",
        "        hx2 = torch.zeros(data.size()[1], 128)\n",
        "        \n",
        "        if use_cuda:\n",
        "            data = data.cuda()\n",
        "            label = label.cuda()\n",
        "            hx1 = hx1.cuda()\n",
        "            hx2 = hx2.cuda()\n",
        "    \n",
        "        accum_loss = 0.0\n",
        "        \n",
        "        for idx_window in range(time_window):\n",
        "            y, hx1, hx2 = model(data[idx_window], hx1, hx2)\n",
        "            loss = criterion(y, label[idx_window])\n",
        "            accum_loss += loss\n",
        "            total_loss += loss.item()\n",
        "            \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "  \n",
        "    elapsed_time = time() - start\n",
        "    print(\"epoch: {}, mean loss: {}, elapsed_time: {}\".format(epoch, total_loss, elapsed_time))\n",
        "\n",
        "# データセットの読み込み・データローダーの設定\n",
        "test_data = BEMSDataset(root=\"./data\", train=False, delay=10, time_window=1)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=1, shuffle=False)\n",
        "\n",
        "# ネットワークを評価モードへ変更\n",
        "model.eval()\n",
        "\n",
        "prediction_result = []\n",
        "        \n",
        "# 評価の実行\n",
        "hx1 = torch.zeros(1, 128)\n",
        "hx2 = torch.zeros(1, 128)\n",
        "if use_cuda:\n",
        "    hx1 = hx1.cuda()\n",
        "    hx2 = hx2.cuda()\n",
        "    \n",
        "with torch.no_grad():\n",
        "    for data, label in test_loader:\n",
        "        \n",
        "        if use_cuda:\n",
        "            data = data.cuda()\n",
        "\n",
        "        y, hx1, hx2 = model(data[0], hx1, hx2)\n",
        "        \n",
        "        prediction_result.append(y.item())\n",
        "\n",
        "prediction_result = np.array(prediction_result).flatten()\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "mse = mean_squared_error(prediction_result, test_data.label)\n",
        "print(\"mse error : {:.4f}\".format(mse))\n",
        "\n",
        "# 結果の表示\n",
        "plt.figure()\n",
        "plt.plot(test_data.label, color='red', label='true')\n",
        "plt.plot(prediction_result.tolist(), color='blue', label='pred')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#課題\n",
        "\n",
        "１．電力予測について，入力データを現在の電力・気温・湿度のみ入力してみましょう"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nFsrjBgubGJy"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyPqCILIa3qcFoC9RE6zFCJ4",
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "01-03_RNN.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
