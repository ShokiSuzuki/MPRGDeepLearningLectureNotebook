{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/machine-perception-robotics-group/MPRGDeepLearningLectureNotebook/blob/master/11_cnn_pytorch/cifar100_resnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJU2RPpSvlQT"
      },
      "source": [
        "# CIFAR100を用いた物体認識（ResNet）\n",
        "\n",
        "\n",
        "---\n",
        "## 目的\n",
        "\n",
        "畳み込みニューラルネットワークのモデルとして，ResNetを用いて実験を行い，その構造を理解する．\n",
        "\n",
        "CIFAR-100データセットを使用してその効果を確認する．"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rQGfxWYK_4O"
      },
      "source": [
        "## 準備\n",
        "\n",
        "### Google Colaboratoryの設定確認・変更\n",
        "本チュートリアルではPyTorchを利用してニューラルネットワークの実装を確認，学習および評価を行います．\n",
        "**GPUを用いて処理を行うために，上部のメニューバーの「ランタイム」→「ランタイムのタイプを変更」からハードウェアアクセラレータをGPUにしてください．**\n",
        "\n",
        "## モジュールのインポート\n",
        "はじめに必要なモジュールをインポートする．\n",
        "\n",
        "### GPUの確認\n",
        "GPUを使用した計算が可能かどうかを確認します．\n",
        "\n",
        "`GPU availability: True`と表示されれば，GPUを使用した計算をChainerで行うことが可能です．\n",
        "Falseとなっている場合は，上記の「Google Colaboratoryの設定確認・変更」に記載している手順にしたがって，設定を変更した後に，モジュールのインポートから始めてください．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iCeaCulfvlao"
      },
      "outputs": [],
      "source": [
        "# モジュールのインポート\n",
        "from time import time\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import torchsummary\n",
        "\n",
        "# GPUの確認\n",
        "use_cuda = torch.cuda.is_available()\n",
        "print('Use CUDA:', use_cuda)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppjeW5MbysXC"
      },
      "source": [
        "## データセットの読み込みと確認\n",
        "\n",
        "学習データ（CIFAR100データセット）を読み込みます．\n",
        "\n",
        "\n",
        "**[CIFAR-100 dataset](https://www.cs.toronto.edu/~kriz/cifar.html)**\n",
        "\n",
        "CIFAR-100 datasetは，CIFAR10を拡張した100クラスの物体認識を行うためのデータセットです．\n",
        "\n",
        "画像サイズは32x32 pixels，学習データ数は50,000, 評価用データ数は10,000とCIFAR-10データセットと同様です．\n",
        "\n",
        "![スクリーンショット 2022-06-29 11.58.51.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/143078/42836b41-034b-012a-cd01-2105917d6761.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K_xx-TkVvls6"
      },
      "outputs": [],
      "source": [
        "transform_train = transforms.Compose([transforms.RandomCrop(32, padding=1),\n",
        "                                      transforms.RandomHorizontalFlip(),\n",
        "                                      transforms.ToTensor()])\n",
        "transform_test = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "train_data = torchvision.datasets.CIFAR100(root=\"./\", train=True, transform=transform_train, download=True)\n",
        "test_data = torchvision.datasets.CIFAR100(root=\"./\", train=False, transform=transform_test, download=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgDd3iX2zmSV"
      },
      "source": [
        "## Residual Networks (ResNet)\n",
        "Residual Networks (ResNet) は，2015年のILSVRCの優勝モデルです．\n",
        "VGGNet[2]で示されたように，ネットワークを深くすることは表現能力を向上させ，認識精度を改善できます．\n",
        "しかし，あまりにも深いネットワークは効率的な学習が困難でした．\n",
        "\n",
        "ResNetは，通常のネットワークのように，何かしらの処理ブロックによる変換$F(x)$を単純に次の層に渡していくのではなく，\n",
        "スキップ構造によりその処理ブロックへの入力$x$をショートカットし， $H(x) = F(x)+x$を次の層に渡すようにしています．\n",
        "スキップ構造により，誤差逆伝播時に勾配が消失しても，層をまたいで値を伝播することができます．\n",
        "このショートカットを含めた処理単位をResidual blockと呼びます．\n",
        "スキップ構造により非常に深いネットワークにおいても効率的に学習ができるようになりました．\n",
        "Residual blockは，3×3 のフィルタサイズを持つ畳み込み層とBatch Normalization，ReLUから構成されています．\n",
        "\n",
        "深いネットワークでは，ある層のパラメータの更新によって，その次の層への入力の分布がバッチ毎に大きく変化してしまう内部共変量シフト (Internal covariate shift) が発生し，学習が効率的に進まない問題がありました．\n",
        "Batch Normalizationは，内部共変量シフトを正規化し，なるべく各層が独立して学習を行えるようにすることで，学習を安定化・高速化する手法です．\n",
        "ResNetでは，このBatch Normalizationとスキップ構造をResidual blockに組み込むことで非常に深いネットワークの学習を実現しています．\n",
        "\n",
        "![ResNet.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/143078/f9491d8f-cb50-6eae-8009-0671a0828446.png)\n",
        "\n",
        "### Basic BlockとBottleneck\n",
        "Residual BlockにはBasic BlockとBottleneckと呼ばれる2種類のResidual blockの構造があります．\n",
        "Basic Blockは3x3の畳み込みを二つ用いた構造となっており，比較的浅いResNet（ResNet-18や34など）使用されます．\n",
        "一方，Bottleneckは1×1, 3×3, 1×1の3つの畳み込みを用いた構造となっており，一度チャンネル数を削減して畳み込みを行い，再度元のチャンネル数に戻すという処理を行っています．Bottleneck構造は深いResNet（ResNet-50, 101, 152など）に用いられます．\n",
        "この2つの構造は同等の計算コストですが，BottleNeck型を採用することで精度を保持しながら計算効率化もできるというメリットがあります．\n",
        "\n",
        "![BasicBlockBottleNeck](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/143078/a642b5c5-ec42-1705-72ab-2911bb82f97e.png)\n",
        "\n",
        "\n",
        "### ImageNet版ResNetとCIFAR10/100版ResNetの違い\n",
        "ImageNet版ResNetとCIFAR10/100版ResNetの違いについては，本ノートブックの下部に記述していますので，興味のある方はご確認ください．\n",
        "\n",
        "## ネットワークモデルの定義\n",
        "\n",
        "Residual Network (ResNet) を定義します．\n",
        "\n",
        "### Residual Block (Basic BlockとBottleneck) の定義\n",
        "まずはじめに，2種類のResidual Block（BasicBlockとBottleneck）を定義します．\n",
        "ここでは，`BasicBlock(nn.Module)`および`Bottleneck(nn.Module)`で，任意の形の構造（チャンネル数など）を定義できるクラスを作成します．\n",
        "`__init__`関数の引数である，`inplanes`は入力される特徴マップのチャンネル数，`planes`はBottleNeck内の特徴マップのチャンネル数を指定します．\n",
        "また，`stride`はResidual Block内の1つ目の3x3の畳み込み層のstrideの値です．\n",
        "`downsample`は，Residual Blockに入力された特徴マップサイズと畳み込み演算後の特徴マップのサイズが異なる場合に元の特徴マップ (resudual) のサイズを調整するための演算を定義するための引数です（詳細は後述）．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AAHq1t-A09Vo"
      },
      "outputs": [],
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super().__init__()\n",
        "        self.convs = nn.Sequential(\n",
        "            nn.Conv2d(inplanes, planes, kernel_size=3, stride=stride, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(planes),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(planes),\n",
        "        )\n",
        "        self.downsample = downsample\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        out = self.convs(x)\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "    def __init__(self, in_planes, planes, stride=1, downsample=None):\n",
        "        super().__init__()\n",
        "        self.convs = nn.Sequential(\n",
        "            nn.Conv2d(in_planes, planes, kernel_size=1, bias=False),\n",
        "            nn.BatchNorm2d(planes),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(planes),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(planes, self.expansion * planes, kernel_size=1, bias=False),\n",
        "            nn.BatchNorm2d(self.expansion * planes),\n",
        "        )\n",
        "        self.downsample = downsample\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        out = self.convs(x)\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hbfz0T6C09Vp"
      },
      "source": [
        "### ResNetの定義\n",
        "上で定義したResidual Blockを活用して，ResNetを定義します．\n",
        "ここでは，使用するResidual Blockの種類に応じて，`ResNetBasicBlock`と`ResNetBottleneck`の2種類のResNetを定義します．\n",
        "\n",
        "`__init__()`内の`depth`は構築したいResNetの層数を指定します（20, 44, 110など）．\n",
        "また，`n_class`はデータセットに応じて，クラス数を指定します．\n",
        "`__init__()`内では，まずはじめに入力された`depth`がResNetを構築することができる数になっているかを確認します．\n",
        "ResNetには，一番最初に単一の畳み込み層と出力層（全結合層）があります．\n",
        "そのため，これら2つの層とResidual Block内の畳み込み層の数の合計が全体の層数となります．\n",
        "また，Residual Blockは特徴マップのサイズに応じて，大きく3つのブロックから構成されています．\n",
        "そのため，ResNetの層数は\n",
        "$$(Res. Block内の畳み込みの数) * (1ブロックあたりのResidual Blockの数) * 3 + 2$$\n",
        "となります．\n",
        "そのため，BasicBlockを用いる際の層数は$6n+2$，Bottleneckを用いる際の層数$9n+2$となります（$n$は1ブロックあたりのResidual Blockの数）．\n",
        "\n",
        "`self._make_layer()`は，任意の形（層数）のResidual Blockからなる層を定義します．\n",
        "Residual Blockに入力されるチャンネル数`planes`，BottleNeckの数`n_blocks`，畳み込みのストライド`stride`を指定します．\n",
        "その後，それらの引数に従い，指定した数・パラメータのBasickBlockまたはBottleneckをリスト内に格納します．\n",
        "最後に，`nn.Sequential`を用いて一塊の層として定義し，任意の数の層を持つresidual blockを定義します（[nn.Sequentialについて](#note)）．\n",
        "\n",
        "このとき，入力される特徴マップのサイズと畳み込み後（残差を計算する際）の特徴マップのサイズが異なる場合に，特徴マップのサイズを調整する`downsample`を定義します．\n",
        "具体的には，特徴マップのサイズを調整することができるstrideで1x1の畳み込みを適用することで，マップのサイズを合わせます．\n",
        "この`downsample`は，調整する必要がある場合に，`BasicBlock`および`Bottleneck`の引数として入力し，活用します．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TNHnp_YczmY3"
      },
      "outputs": [],
      "source": [
        "class ResNetBasicBlock(nn.Module):\n",
        "    def __init__(self, depth, n_class=10):\n",
        "        super().__init__()\n",
        "        # 指定した深さ（畳み込みの層数）でネットワークを構築できるかを確認\n",
        "        assert (depth - 2) % 6 == 0, 'When use basicblock, depth should be 6n+2 (e.g. 20, 32, 44).'\n",
        "        n_blocks = (depth - 2) // 6  # 1ブロックあたりのBasic Blockの数を決定\n",
        "\n",
        "        self.inplanes = 16\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.layer1 = self._make_layer(16, n_blocks)\n",
        "        self.layer2 = self._make_layer(32, n_blocks, stride=2)\n",
        "        self.layer3 = self._make_layer(64, n_blocks, stride=2)\n",
        "\n",
        "        self.avgpool = nn.AvgPool2d(8)\n",
        "        self.fc = nn.Linear(64 * BasicBlock.expansion, n_class)\n",
        "\n",
        "    def _make_layer(self, planes, n_blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * BasicBlock.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.inplanes, planes * BasicBlock.expansion, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes * BasicBlock.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(BasicBlock(self.inplanes, planes, stride, downsample))\n",
        "        self.inplanes = planes * BasicBlock.expansion\n",
        "        for _ in range(0, n_blocks - 1):\n",
        "            layers.append(BasicBlock(self.inplanes, planes))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class ResNetBottleneck(nn.Module):\n",
        "    def __init__(self, depth, n_class=10):\n",
        "        super().__init__()\n",
        "        # 指定した深さ（畳み込みの層数）でネットワークを構築できるかを確認\n",
        "        assert (depth - 2) % 9 == 0, 'When use Bottleneck, depth should be 9n+2 (e.g. 47, 56, 110, 1199).'\n",
        "        n_blocks = (depth - 2) // 9  # 1ブロックあたりのBasic Blockの数を決定\n",
        "\n",
        "        self.inplanes = 16\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.layer1 = self._make_layer(16, n_blocks)\n",
        "        self.layer2 = self._make_layer(32, n_blocks, stride=2)\n",
        "        self.layer3 = self._make_layer(64, n_blocks, stride=2)\n",
        "\n",
        "        self.avgpool = nn.AvgPool2d(8)\n",
        "        self.fc = nn.Linear(64 * Bottleneck.expansion, n_class)\n",
        "\n",
        "    def _make_layer(self, planes, n_blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * Bottleneck.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.inplanes, planes * Bottleneck.expansion, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes * Bottleneck.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(Bottleneck(self.inplanes, planes, stride, downsample))\n",
        "        self.inplanes = planes * Bottleneck.expansion\n",
        "        for _ in range(0, n_blocks - 1):\n",
        "            layers.append(Bottleneck(self.inplanes, planes))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Dwuvfouzmd7"
      },
      "source": [
        "## ネットワークの作成\n",
        "上のプログラムで定義したネットワークを作成します．\n",
        "使用したいResdual Block構造の種類に応じて，層数を指定します．\n",
        "\n",
        "CNNクラスを呼び出して，ネットワークモデルを定義します． \n",
        "また，GPUを使う場合（`use_cuda == True`）には，ネットワークモデルをGPUメモリ上に配置します． \n",
        "これにより，GPUを用いた演算が可能となります．\n",
        "\n",
        "学習を行う際の最適化方法としてモーメンタムSGD (モーメンタム付き確率的勾配降下法) を利用します． \n",
        "また，学習率を0.01，モーメンタムを0.9として引数に与えます．\n",
        "\n",
        "最後に，定義したネットワークの詳細情報を`torchsummary.summary()`関数を用いて表示します．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23m79Eq-zmjl"
      },
      "outputs": [],
      "source": [
        "# ResNetの層数を指定 (e.g. 20, 32, 44, 47, 56, 110, 1199)\n",
        "n_layers = 20\n",
        "\n",
        "# ResNetを構築 (どちらか一方を残してください)\n",
        "model = ResNetBasicBlock(depth=n_layers, n_class=100)    # BasicBlock構造を用いる場合\n",
        "# model = ResNetBottleneck(depth=n_layers, n_class=100)  # Bottleneck構造を用いる場合\n",
        "\n",
        "if use_cuda:\n",
        "    model.cuda()\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "# モデルの情報を表示\n",
        "torchsummary.summary(model, (3, 32, 32))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUNa9Xe79vAG"
      },
      "source": [
        "## 学習\n",
        "１回の誤差を算出するデータ数（ミニバッチサイズ）を128，学習エポック数を100とします．\n",
        "CIFAR10の学習データサイズを取得し，１エポック内における更新回数を求めます．\n",
        "学習モデルに`image`を与えて各クラスの確率yを取得します．各クラスの確率yと教師ラベル`label`との誤差をsoftmax coross entropy誤差関数で算出します．\n",
        "また，認識精度も算出します．そして，誤差をbackward関数で逆伝播し，ネットワークの更新を行います．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "68RE3RTa76-W"
      },
      "outputs": [],
      "source": [
        "# ミニバッチサイズ・エポック数の設定\n",
        "batch_size = 128\n",
        "epoch_num = 10\n",
        "\n",
        "# データローダーの設定\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "# 誤差関数の設定\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "if use_cuda:\n",
        "    criterion.cuda()\n",
        "\n",
        "# ネットワークを学習モードへ変更\n",
        "model.train()\n",
        "\n",
        "start = time()\n",
        "for epoch in range(1, epoch_num+1):\n",
        "    sum_loss = 0.0\n",
        "    count = 0\n",
        "    \n",
        "    for image, label in train_loader:\n",
        "        if use_cuda:\n",
        "            image = image.cuda()\n",
        "            label = label.cuda()\n",
        "\n",
        "        y = model(image)\n",
        "        loss = criterion(y, label)\n",
        "        \n",
        "        model.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        sum_loss += loss.item()\n",
        "        \n",
        "        pred = torch.argmax(y, dim=1)\n",
        "        count += torch.sum(pred == label)\n",
        "\n",
        "    print(\"epoch: {}, mean loss: {}, mean accuracy: {}, elapsed_time :{}\".format(epoch,\n",
        "                                                                                 sum_loss / len(train_loader),\n",
        "                                                                                 count.item() / len(train_data),\n",
        "                                                                                 time() - start))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "119eIrSmzmw6"
      },
      "source": [
        "## テスト\n",
        "学習したネットワークモデルを用いて評価を行います．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yoYVMRGLzm1I"
      },
      "outputs": [],
      "source": [
        "# データローダーの準備\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=100, shuffle=False)\n",
        "\n",
        "# ネットワークを評価モードへ変更\n",
        "model.eval()\n",
        "\n",
        "# 評価の実行\n",
        "count = 0\n",
        "with torch.no_grad():\n",
        "    for image, label in test_loader:\n",
        "\n",
        "        if use_cuda:\n",
        "            image = image.cuda()\n",
        "            label = label.cuda()\n",
        "            \n",
        "        y = model(image)\n",
        "\n",
        "        pred = torch.argmax(y, dim=1)\n",
        "        count += torch.sum(pred == label)\n",
        "\n",
        "print(\"test accuracy: {}\".format(count.item() / len(test_data)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_U8wsW37hUUI"
      },
      "source": [
        "## 課題\n",
        "\n",
        "\n",
        "### 1. 学習の設定を変更し，認識精度の変化を確認しましょう．\n",
        "\n",
        "**ヒント：プログラムの中で変更で切る設定は次のようなものが存在します．**\n",
        "* ミニバッチサイズ\n",
        "* 学習回数（Epoch数）\n",
        "* 学習率\n",
        "* 最適化手法\n",
        "  * `torch.optim.Adagrad()`や`torch.optim.Adam()`などが考えられます．\n",
        "  * PyTorchで使用できる最適化手法は[こちらのページ](https://pytorch.org/docs/stable/optim.html#algorithms)にまとめられています．\n",
        "\n",
        "\n",
        "### 2. Data Augmentationの種類を追加して学習を行いましょう．\n",
        "\n",
        "**ヒント**\n",
        "：学習時に使用するData Augmentationは`transform_train`の部分で変更できます．\n",
        "\n",
        "```python\n",
        "transform_train = transforms.Compose([(この部分に使用するAugmentationの処理を追加) ,\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.LinearTransformation(Z, mean)])\n",
        "```\n",
        "\n",
        "PyTorch（torchvision）で使用可能な変換は[こちらのページ](https://pytorch.org/vision/stable/transforms.html)にまとめられています．\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ocz20KS709Vu"
      },
      "source": [
        "## 備考\n",
        "<a id='note'></a>\n",
        "\n",
        "### nn.Sequential()について\n",
        "また，層を定義する`__init__`内では，`nn.Sequential()`という関数が用いられています．\n",
        "これは，複数の層が格納されたリストを引数として受け取り，これらの層をひとまとめにしたオブジェクト（層）を定義する関数です・\n",
        "下の関数では，畳み込みやBatchNormalizationがリスト内にされています．\n",
        "`nn.Sequential`で定義した層`self.convs`では，実際に演算する際，すなわち`formward()`関数内では，`self.convs(x)`とすることで，リストに格納した演算をその順番通りに処理して返すことができます．\n",
        "\n",
        "### ImageNet版ResNetとCIFAR10/100版ResNetの違い\n",
        "このノートブックで実装したResNetは，ResNetの元論文でCIFAR10/100の分類実験に使用された構造を定義しています．\n",
        "ResNetには大きく，ImageNet版とCIFAR版があり，今日広く用いられているモデルはImageNet版となります．\n",
        "ImageNetとCIFAR版の主な違いは以下の通りです．\n",
        "\n",
        "|                   | ImageNet | CIFAR |\n",
        "|-------------------|----------|-------|\n",
        "| 1層目の畳み込みのカーネルサイズ | 7x7 | 3x3 |\n",
        "| 1層目の畳み込み後の特徴マップチャンネル数 | 64 | 16 |\n",
        "| 複数のRes. Blockを統合したブロックの数 | 4 | 3 |\n",
        "| 各ブロック内のRes. Blockの数 | 構造・ブロックによって異なる | `(層数 - 2) // 6` (Basicblock) または `(層数 - 2) // 9` (BottleNeck) |\n",
        "\n",
        "ImageNet版のResNetは`torchvision.models`に実装されており，学習済みモデルなども公開されています（[torchvisionのResNetリファレンスページ](https://pytorch.org/vision/stable/models.html#id10)）．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-q9ZLK1509Vu"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "cifar100_resnet.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}